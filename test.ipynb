{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38e210cd-de41-4b5a-b63b-2acc512906ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import threading\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "#executable_path = \"C:\\webdriver\\chromedriver.exe\"\n",
    "\n",
    "class Scraper:\n",
    "    \n",
    "    def __call__(self):\n",
    "        \n",
    "        # Changing chromedriver default options\n",
    "        options = Options()\n",
    "        options.headless = False # Change to False if you want it to happen visually\n",
    "        options.add_argument(\"--start-maximized\") #Headless = True\n",
    "        \n",
    "        max_workers = 1\n",
    "        drivers = []\n",
    "        threads = []\n",
    "        dataframes = [pd.DataFrame() for _ in range(max_workers)]\n",
    "        links = []\n",
    "\n",
    "        def cookies(driver):\n",
    "            driver.get('https://www.betcity.nl/sportsbook#sports-hub/volleyball')\n",
    "            \n",
    "            # Cookie button\n",
    "            try:\n",
    "                WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"CybotCookiebotDialogBodyButtonAccept\"]')))\n",
    "                time.sleep(5)\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"CybotCookiebotDialogBodyButtonAccept\"]').click()\n",
    "            except: \n",
    "                return\n",
    "            \n",
    "        # Scrapes a soccer league on Betcity\n",
    "        def scrape(driver, link, worker):\n",
    "            \n",
    "            # List of team-names: ['teamname1'\\n'teamname2', ....]\n",
    "            names = []\n",
    "            # List of hyperlinks to bets\n",
    "            bet_links = []\n",
    "            # List of 1x2 odds\n",
    "            result_list = []\n",
    "            # List of over/under odds\n",
    "            over_under_list = []\n",
    "            # List of first half over/under odds\n",
    "            over_under_1e_list = []\n",
    "            # List of second half over/under odds\n",
    "            over_under_2e_list = []\n",
    "            # List of handicap odds\n",
    "            handicap_list = []\n",
    "            # List of dubbele kans odds\n",
    "            dubbele_kans_list = []\n",
    "            # List of Beide teams scoren\n",
    "            beide_teams_scoren_list = []\n",
    "            # List of first half Beide teams scoren\n",
    "            beide_teams_scoren_1e_list = []\n",
    "            # List of second half Beide teams scoren\n",
    "            beide_teams_scoren_2e_list = []\n",
    "            \n",
    "            def click(webElement):\n",
    "                ActionChains(driver).move_to_element(webElement)\n",
    "                webElement.click()\n",
    "                \n",
    "            def wait(xpath):\n",
    "                try:\n",
    "                    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "                except: \n",
    "                    return\n",
    "                \n",
    "            def scrape_result():\n",
    "                # Find all 1x2 odds\n",
    "                try:\n",
    "                    #result = driver.find_element(By.XPATH, \".//li[@class='KambiBC-bet-offer-subcategory KambiBC-bet-offer-subcategory--onecrosstwo']\")\n",
    "                    result = driver.find_element(By.XPATH, \".//li[@class='KambiBC-sandwich-filter__event-list-info']\")\n",
    "                except:\n",
    "                    return False\n",
    "                    \n",
    "                # Add the teamnames to the right list\n",
    "                teamNames = result.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[1]\")\n",
    "                names.append(teamNames[0].text + \"\\n\" + teamNames[2].text)\n",
    "                    \n",
    "                # Add the result odds to the right list\n",
    "                result_odds = result.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[2]\")\n",
    "                \n",
    "                if len(result_odds) < 3:\n",
    "                    result_list.append(\"1.0\\n1.0\\n1.0\")\n",
    "                    return True\n",
    "                \n",
    "                result_list.append(result_odds[0].text + \"\\n\" + result_odds[1].text + \"\\n\" + result_odds[2].text)\n",
    "                return True\n",
    "            \n",
    "            def scrape_dubbele_kans():\n",
    "                # Find all dubbele kans odds\n",
    "                try:\n",
    "                    dubbele_kans = driver.find_element(By.XPATH, \".//li[@class='KambiBC-bet-offer-subcategory KambiBC-bet-offer-subcategory--doublechance']\")\n",
    "                except:\n",
    "                    dubbele_kans_list.append(\"1.0\\n1.0\\n1.0\")\n",
    "                    return\n",
    "                    \n",
    "                # Add all the dubbele kans odds to the right list\n",
    "                dubbele_kans_odds = dubbele_kans.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[2]\")\n",
    "                \n",
    "                if len(dubbele_kans_odds) < 3:\n",
    "                    dubbele_kans_list.append(0)\n",
    "                    return\n",
    "                \n",
    "                dubbele_kans_list.append(dubbele_kans_odds[0].text + \"\\n\" + dubbele_kans_odds[1].text + \"\\n\" + dubbele_kans_odds[2].text)\n",
    "            \n",
    "            def scrape_over_under():\n",
    "                # The string that contains the odds for all over/under bets\n",
    "                over_under_string = \"\"\n",
    "                    \n",
    "                # Find all over/under odds\n",
    "                try:\n",
    "                    over_under = driver.find_element(By.XPATH, \".//li[@class='KambiBC-bet-offer-subcategory KambiBC-bet-offer-subcategory--overunder']\")\n",
    "                except:\n",
    "                    over_under_list.append(0)\n",
    "                    return\n",
    "                    \n",
    "                # Show the over/under odds\n",
    "                lijst_tonen(over_under)\n",
    "                \n",
    "                # Find the odds\n",
    "                over_under_odds = over_under.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button\")\n",
    "                  \n",
    "                # The amount of over under odds\n",
    "                n = int(len(over_under_odds)/2)\n",
    "                \n",
    "                # Add all the over under odds to a formatted string\n",
    "                for i in range(n):\n",
    "                    number = over_under_odds[i].find_element(By.XPATH, \".//div/div[1]/div[2]\").text\n",
    "                    try:\n",
    "                        odd_over = over_under_odds[i].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_over = \"1\"\n",
    "                    try:\n",
    "                        odd_under = over_under_odds[i + n].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_under = \"1\"\n",
    "                    over_under_string += number + \"\\n\" + odd_over + \"\\n\" + odd_under + \"|\"\n",
    "                \n",
    "                # Add all the over/under odds to the right list\n",
    "                over_under_list.append(over_under_string)\n",
    "            \n",
    "            def scrape_beide_teams_scoren():\n",
    "                # Find the beide teams scoren totaal odds\n",
    "                try:\n",
    "                    beide_teams_scoren = driver.find_element(By.XPATH, \".//li[div[div[div[h3[span[text()='Beide teams scoren']]]]]]\")\n",
    "                except:\n",
    "                    beide_teams_scoren_list.append(0)\n",
    "                    return\n",
    "                    \n",
    "                # Get all beide teams scoren odds on the game and then put them in the list\n",
    "                beide_teams_scoren_odds = beide_teams_scoren.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[2]\")\n",
    "                \n",
    "                if len(beide_teams_scoren_odds) < 2:\n",
    "                    beide_teams_scoren_list.append(0)\n",
    "                    return\n",
    "                \n",
    "                beide_teams_scoren_list.append(beide_teams_scoren_odds[0].text + \"\\n\" + beide_teams_scoren_odds[1].text)\n",
    "            \n",
    "            def scrape_handicap():\n",
    "                # The string that contains the odds for all handicaps\n",
    "                handicap_string = \"\"\n",
    "                    \n",
    "                # Click to see all handicap bets\n",
    "                try:\n",
    "                    asian = driver.find_element(By.XPATH, \".//li[div[header[div[div[contains(text(), 'Asian Lines')]]]]]\") \n",
    "                except:\n",
    "                   handicap_list.append(0)\n",
    "                   return\n",
    "                    \n",
    "                # Move to the asian subbets and open them\n",
    "                click(asian)\n",
    "                \n",
    "                # Let the data load\n",
    "                time.sleep(0.5)\n",
    "                    \n",
    "                # Find all handicap odds\n",
    "                handicap = driver.find_element(By.XPATH, \".//li[@class='KambiBC-bet-offer-subcategory KambiBC-bet-offer-subcategory--asian']\")\n",
    "                    \n",
    "                # Show the handicap odds\n",
    "                lijst_tonen(handicap)\n",
    "                    \n",
    "                # Find the handicap odds\n",
    "                numbers = handicap.find_elements(By.XPATH, \".//div[1][@class='KambiBC-outcomes-list__column']/button/div/div[1]/div[2]\")\n",
    "                handicap_home_odds = handicap.find_elements(By.XPATH, \".//div[1][@class='KambiBC-outcomes-list__column']/button/div/div[2]/div[2]\")\n",
    "                handicap_away_odds = handicap.find_elements(By.XPATH, \".//div[2][@class='KambiBC-outcomes-list__column']/button/div/div[2]/div[2]\")\n",
    "                    \n",
    "                # Add all the handicap odds to a formatted string\n",
    "                for i in range(len(handicap_home_odds)):\n",
    "                    number = numbers[i].text\n",
    "                    if number.find(\".5\") == -1:\n",
    "                        continue\n",
    "                    odd_home = handicap_home_odds[i].text\n",
    "                    odd_away = handicap_away_odds[i].text\n",
    "                    handicap_string += number + \"\\n\" + odd_home + \"\\n\" + odd_away + \"|\"\n",
    "                \n",
    "                # Add all the handicap odds to the right list\n",
    "                handicap_list.append(handicap_string)\n",
    "            \n",
    "            def scrape_halves():\n",
    "                # Click to see all half category bets\n",
    "                try:\n",
    "                    half = driver.find_element(By.XPATH, \".//li[div[header[div[div[contains(text(), 'Helft')]]]]]\") \n",
    "                except:\n",
    "                    over_under_1e_list.append(0)\n",
    "                    over_under_2e_list.append(0)\n",
    "                    beide_teams_scoren_1e_list.append(0)\n",
    "                    beide_teams_scoren_2e_list.append(0)\n",
    "                    return\n",
    "                \n",
    "                # Move to the half category subbets and open them\n",
    "                click(half)\n",
    "                \n",
    "                # Let the data load\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                # Scrape the over/under bets from the first half\n",
    "                try:\n",
    "                    scrape_over_under_1e(driver.find_element(By.XPATH, \".//li[div[div[div[h3[span[text()='Totaal aantal doelpunten - 1e Helft']]]]]]\"))\n",
    "                except:\n",
    "                    over_under_1e_list.append(0)\n",
    "                \n",
    "                # Scrape the over/under bets from the second half\n",
    "                try:\n",
    "                    scrape_over_under_2e(driver.find_element(By.XPATH, \".//li[div[div[div[h3[span[text()='Totaal aantal doelpunten - 2e Helft']]]]]]\"))\n",
    "                except:\n",
    "                    over_under_2e_list.append(0)\n",
    "                \n",
    "                # Scrape the beide teams winnen bets from the first half\n",
    "                try:\n",
    "                    scrape_beide_teams_scoren_1e(driver.find_element(By.XPATH, \".//li[div[div[div[h3[span[text()='Beide teams scoren - 1e Helft']]]]]]\"))\n",
    "                except:\n",
    "                    beide_teams_scoren_1e_list.append(0)\n",
    "                    \n",
    "                # Scrape the over/under bets from the second half\n",
    "                try:\n",
    "                    scrape_beide_teams_scoren_2e(driver.find_element(By.XPATH, \".//li[div[div[div[h3[span[text()='Beide teams scoren - 2e Helft']]]]]]\"))\n",
    "                except:\n",
    "                    beide_teams_scoren_2e_list.append(0)\n",
    "                \n",
    "            def scrape_over_under_1e(over_under):\n",
    "                # The string that contains the odds for all over/under bets\n",
    "                over_under_string = \"\"\n",
    "                \n",
    "                # Click on the lijst tonen button if it exists\n",
    "                lijst_tonen(over_under)\n",
    "                \n",
    "                # Find the odds\n",
    "                over_under_odds = over_under.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button\")\n",
    "                \n",
    "                # The amount of over under odds\n",
    "                n = int(len(over_under_odds)/2)\n",
    "                \n",
    "                # Add all the over under odds to a formatted string\n",
    "                for i in range(n):\n",
    "                    number = over_under_odds[i].find_element(By.XPATH, \".//div/div[1]/div[2]\").text\n",
    "                    try:\n",
    "                        odd_over = over_under_odds[i].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_over = \"1\"\n",
    "                    try:\n",
    "                        odd_under = over_under_odds[i + n].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_under = \"1\"\n",
    "                    over_under_string += number + \"\\n\" + odd_over + \"\\n\" + odd_under + \"|\"\n",
    "                \n",
    "                # Add all the over/under odds to the right list\n",
    "                over_under_1e_list.append(over_under_string)\n",
    "                \n",
    "            def scrape_over_under_2e(over_under):\n",
    "                # The string that contains the odds for all over/under bets\n",
    "                over_under_string = \"\"\n",
    "                    \n",
    "                # Click on the lijst tonen button if it exists\n",
    "                lijst_tonen(over_under)\n",
    "                \n",
    "                # Find the odds\n",
    "                over_under_odds = over_under.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button\")\n",
    "                  \n",
    "                # The amount of over under odds\n",
    "                n = int(len(over_under_odds)/2)\n",
    "                \n",
    "                # Add all the over under odds to a formatted string\n",
    "                for i in range(n):\n",
    "                    number = over_under_odds[i].find_element(By.XPATH, \".//div/div[1]/div[2]\").text\n",
    "                    try:\n",
    "                        odd_over = over_under_odds[i].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_over = \"1\"\n",
    "                    try:\n",
    "                        odd_under = over_under_odds[i + n].find_element(By.XPATH, \".//div/div[2]/div[2]\").text\n",
    "                    except:\n",
    "                        odd_under = \"1\"\n",
    "                    over_under_string += number + \"\\n\" + odd_over + \"\\n\" + odd_under + \"|\"\n",
    "                \n",
    "                # Add all the over/under odds to the right list\n",
    "                over_under_2e_list.append(over_under_string)\n",
    "                \n",
    "            def scrape_beide_teams_scoren_1e(beide_teams_scoren):\n",
    "                # Get all beide teams scoren odds on the game and then put them in the list\n",
    "                beide_teams_scoren_odds = beide_teams_scoren.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[2]\")\n",
    "                \n",
    "                if len(beide_teams_scoren_odds) < 2:\n",
    "                    beide_teams_scoren_1e_list.append(0)\n",
    "                    return\n",
    "                \n",
    "                beide_teams_scoren_1e_list.append(beide_teams_scoren_odds[0].text + \"\\n\" + beide_teams_scoren_odds[1].text)\n",
    "                \n",
    "            def scrape_beide_teams_scoren_2e(beide_teams_scoren):\n",
    "                # Get all beide teams scoren odds on the game and then put them in the list\n",
    "                beide_teams_scoren_odds = beide_teams_scoren.find_elements(By.XPATH, \".//div[@class='KambiBC-outcomes-list__column']/button/div/div[2]\")\n",
    "                \n",
    "                if len(beide_teams_scoren_odds) < 2:\n",
    "                    beide_teams_scoren_2e_list.append(0)\n",
    "                    return\n",
    "                \n",
    "                beide_teams_scoren_2e_list.append(beide_teams_scoren_odds[0].text + \"\\n\" + beide_teams_scoren_odds[1].text)\n",
    "            \n",
    "            # A function that presses on Lijst tonen if it exists\n",
    "            def lijst_tonen(webElement):\n",
    "                try:\n",
    "                    button = webElement.find_element(By.XPATH, \".//button[@class='KambiBC-outcomes-list__toggler-toggle-button']\")\n",
    "                except:\n",
    "                    return\n",
    "                \n",
    "                click(button)\n",
    "            \n",
    "            driver.get(link)\n",
    "            \n",
    "            # The links of all singular matches\n",
    "            matchLinks = []\n",
    "        \n",
    "            # Wait for the data to load\n",
    "            try:\n",
    "                wait(\".//ul[@class='KambiBC-sandwich-filter__list']\")\n",
    "            except:\n",
    "                print(\"Competition not found\")\n",
    "                return\n",
    "        \n",
    "            # Find all matches\n",
    "            matches = driver.find_elements(By.XPATH, \".//li[@class='KambiBC-sandwich-filter__event-list-item']\")\n",
    "            \n",
    "            # Loop through each match to extract the links\n",
    "            for match in matches:\n",
    "                current_day = time.localtime()[6]\n",
    "                try:\n",
    "                    match_day = match.find_element(By.XPATH, \".//span[@class='KambiBC-event-item__start-time--date']\").text\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                if match_day == \"ma\":\n",
    "                    match_day = 0\n",
    "                elif match_day == \"di\":\n",
    "                    match_day = 1\n",
    "                elif match_day == \"wo\":\n",
    "                    match_day = 2\n",
    "                elif match_day == \"do\":\n",
    "                    match_day = 3\n",
    "                elif match_day == \"vr\":\n",
    "                    match_day = 4\n",
    "                elif match_day == \"za\":\n",
    "                    match_day = 5\n",
    "                elif match_day == \"zo\":\n",
    "                    match_day = 6\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                date_diff = match_day - current_day\n",
    "                if current_day != 6:\n",
    "                    if date_diff < 0 or date_diff > 1 :\n",
    "                        continue\n",
    "                else:\n",
    "                    if match_day != 0 and match_day != 6:\n",
    "                        continue\n",
    "                    \n",
    "                link = match.find_element(By.XPATH, \".//a\").get_attribute('href')\n",
    "                try:\n",
    "                    amount = int(match.find_element(By.XPATH, \".//div[@class='KambiBC-sandwich-filter_show-more-right-text']\").text.split(\"B\", 1)[0])\n",
    "                except:\n",
    "                    continue\n",
    "                if link.find('live') == -1 and amount > 40:\n",
    "                    matchLinks.append(link)\n",
    "        \n",
    "            # Visit each single match to extract the needed data\n",
    "            for link in matchLinks:\n",
    "                driver.get(link)\n",
    "                \n",
    "                # Wait for the data to load\n",
    "                wait(\".//button[@class='KambiBC-outcomes-list__toggler-toggle-button']\")\n",
    "                \n",
    "                # Scrape the result data\n",
    "                if not scrape_result():\n",
    "                    continue\n",
    "                \n",
    "                bet_links.append(driver.current_url)\n",
    "                \n",
    "                # Scrape the dubbele kans data\n",
    "                scrape_dubbele_kans()\n",
    "                \n",
    "                # Scrape the over/under data\n",
    "                scrape_over_under()\n",
    "                \n",
    "                # Scrape the beide teams scoren data\n",
    "                scrape_beide_teams_scoren()\n",
    "                \n",
    "                # Scrape the handicap data\n",
    "                scrape_handicap()\n",
    "                \n",
    "                # Scrape the halves odds category data\n",
    "                scrape_halves()\n",
    "                \n",
    "            # After each competition we create a dataframe with the odds that we have so far collected\n",
    "            dict_worker = {'Teams': names, 'result' : result_list, 'over_under' : over_under_list, 'over_under_1e' : over_under_1e_list,\n",
    "                        'over_under_2e' : over_under_2e_list, 'handicap' : handicap_list, 'beide_teams_scoren' : beide_teams_scoren_list,\n",
    "                        'beide_teams_scoren_1e' : beide_teams_scoren_1e_list, 'beide_teams_scoren_2e' : beide_teams_scoren_2e_list, 'dubbele_kans' : dubbele_kans_list, 'bet_links' : bet_links}\n",
    "        \n",
    "            dataframes[worker] = pd.concat([dataframes[worker], pd.DataFrame.from_dict(dict_worker)])\n",
    "        \n",
    "        \n",
    "        ## Run the Scraper\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with open('betcity_volly.txt', 'r') as f:\n",
    "            links = f.read().split('\\n')\n",
    "        \n",
    "        amount_links = len(links)\n",
    "        links_used = 0\n",
    "        \n",
    "        for i in range(0, max_workers):\n",
    "            #drivers.append(webdriver.Chrome(executable_path=executable_path,options=options))\n",
    "            drivers.append(webdriver.Chrome(options=options))\n",
    "            threads.append(threading.Thread(target=cookies, args=[drivers[i]]))\n",
    "            threads[i].start()\n",
    "        \n",
    "        while True:\n",
    "            skip = False\n",
    "            \n",
    "            try:\n",
    "                df_betcity = pd.concat([i for i in dataframes if not i.empty])\n",
    "            except:\n",
    "                skip = True\n",
    "            \n",
    "            stop = True\n",
    "            \n",
    "            for i in range(max_workers):\n",
    "                if links_used >= amount_links:\n",
    "                    if threads[i].is_alive():\n",
    "                        stop = False\n",
    "                        \n",
    "                elif not threads[i].is_alive():\n",
    "                    if links[links_used] == '':\n",
    "                        links_used += 1\n",
    "                        continue\n",
    "                    \n",
    "                    threads[i] = threading.Thread(target=scrape, args=[drivers[i], links[links_used], i])\n",
    "                    threads[i].start()\n",
    "                    links_used += 1\n",
    "                    stop = False\n",
    "                    \n",
    "                else: stop = False\n",
    "            \n",
    "            if skip:\n",
    "                continue\n",
    "            \n",
    "            output = open('df_betcity_volly', 'wb')\n",
    "            pickle.dump(df_betcity, output)\n",
    "            output.close()\n",
    "            \n",
    "            if stop:\n",
    "                break\n",
    "            \n",
    "            time.sleep(1)\n",
    "        \n",
    "        for driver in drivers:\n",
    "            driver.quit()\n",
    "            \n",
    "        print(\"Betcity finished in: %s seconds\" % int((time.time() - start_time)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851b6cd-1739-4708-97fe-8b13246c4b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b259578e-e16c-4153-b114-b6745987b19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'betcity_volly.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0a5b82058260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mScraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mScraper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-85655f6dcfca>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'betcity_volly.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m             \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'betcity_volly.txt'"
     ]
    }
   ],
   "source": [
    "Scraper.__call__(Scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fe162-1ef8-410d-8492-be3e673884bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
